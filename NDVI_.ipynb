{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mERYCEff-dfh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "S3bHcN8agXPf",
        "outputId": "afb61878-cba4-4638-c183-18205c714d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e95a95d6-fa70-4efa-910a-71b035b98709\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e95a95d6-fa70-4efa-910a-71b035b98709\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hacktest.csv to hacktest.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtask 1: Data Loading & Initial Checks\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load Data\n",
        "train_df = pd.read_csv(\"hacktrain.csv\")   # or your train filename\n",
        "test_df  = pd.read_csv(\"hacktest.csv\")    # or your test filename\n",
        "\n",
        "# 2. Basic Info Check\n",
        "print(\">>> TRAIN shape:\", train_df.shape)\n",
        "print(train_df.head())\n",
        "print(train_df.info())\n",
        "print(\"\\n>>> TEST shape:\", test_df.shape)\n",
        "print(test_df.head())\n",
        "print(test_df.info())\n",
        "\n",
        "# 3. Identify NDVI columns\n",
        "ndvi_cols = [c for c in train_df.columns if c.endswith('_N')]\n",
        "print(f\"\\nFound {len(ndvi_cols)} NDVI columns:\")\n",
        "print(ndvi_cols)\n",
        "\n",
        "# 4. Class label distribution (train only)\n",
        "print(\"\\nClass counts:\")\n",
        "print(train_df['class'].value_counts())\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "train_df['class'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Land Cover Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# 5. Null value summary\n",
        "print(\"\\nMissing values in TRAIN:\")\n",
        "print(train_df[ndvi_cols].isnull().sum().sort_values(ascending=False).head(10))\n",
        "print(\"\\nMissing values in TEST:\")\n",
        "print(test_df[ndvi_cols].isnull().sum().sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QKdrPOuHgSRm",
        "outputId": "cfbaf0aa-92b4-484d-e0d6-8a8809c94075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> TRAIN shape: (8000, 30)\n",
            "   Unnamed: 0  ID  class  20150720_N  20150602_N  20150517_N  20150501_N  \\\n",
            "0           0   1  water    637.5950     658.668   -1882.030    -1924.36   \n",
            "1           1   2  water    634.2400     593.705   -1625.790    -1672.32   \n",
            "2           3   4  water     58.0174   -1599.160         NaN    -1052.63   \n",
            "3           4   5  water     72.5180         NaN     380.436    -1256.93   \n",
            "4           7   8  water   1136.4400         NaN         NaN     1647.83   \n",
            "\n",
            "   20150415_N  20150330_N  20150314_N  ...  20140610_N  20140525_N  \\\n",
            "0     997.904   -1739.990     630.087  ...         NaN   -1043.160   \n",
            "1     914.198    -692.386     707.626  ...         NaN    -933.934   \n",
            "2         NaN   -1564.630         NaN  ...    -1025.88     368.622   \n",
            "3     515.805   -1413.180    -802.942  ...    -1813.95     155.624   \n",
            "4    1935.800         NaN    2158.980  ...     1535.00    1959.430   \n",
            "\n",
            "   20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  20140202_N  \\\n",
            "0   -1942.490     267.138         NaN         NaN     211.328   -2203.020   \n",
            "1    -625.385     120.059     364.858     476.972     220.878   -2250.000   \n",
            "2         NaN   -1227.800     304.621         NaN     369.214   -2202.120   \n",
            "3         NaN    -924.073     432.150     282.833     298.320   -2197.360   \n",
            "4    -279.317    -384.915    -113.406    1020.720    1660.650    -116.801   \n",
            "\n",
            "   20140117_N  20140101_N  \n",
            "0    -1180.19     433.906  \n",
            "1    -1360.56     524.075  \n",
            "2         NaN   -1343.550  \n",
            "3         NaN    -826.727  \n",
            "4     -568.05   -1357.140  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8000 entries, 0 to 7999\n",
            "Data columns (total 30 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Unnamed: 0  8000 non-null   int64  \n",
            " 1   ID          8000 non-null   int64  \n",
            " 2   class       8000 non-null   object \n",
            " 3   20150720_N  7440 non-null   float64\n",
            " 4   20150602_N  6800 non-null   float64\n",
            " 5   20150517_N  7200 non-null   float64\n",
            " 6   20150501_N  7040 non-null   float64\n",
            " 7   20150415_N  7520 non-null   float64\n",
            " 8   20150330_N  6880 non-null   float64\n",
            " 9   20150314_N  7280 non-null   float64\n",
            " 10  20150226_N  6640 non-null   float64\n",
            " 11  20150210_N  7360 non-null   float64\n",
            " 12  20150125_N  6960 non-null   float64\n",
            " 13  20150109_N  7120 non-null   float64\n",
            " 14  20141117_N  6720 non-null   float64\n",
            " 15  20141101_N  7600 non-null   float64\n",
            " 16  20141016_N  6560 non-null   float64\n",
            " 17  20140930_N  7200 non-null   float64\n",
            " 18  20140813_N  7440 non-null   float64\n",
            " 19  20140626_N  6400 non-null   float64\n",
            " 20  20140610_N  7520 non-null   float64\n",
            " 21  20140525_N  7280 non-null   float64\n",
            " 22  20140509_N  7120 non-null   float64\n",
            " 23  20140423_N  6240 non-null   float64\n",
            " 24  20140407_N  7360 non-null   float64\n",
            " 25  20140322_N  6880 non-null   float64\n",
            " 26  20140218_N  6560 non-null   float64\n",
            " 27  20140202_N  7440 non-null   float64\n",
            " 28  20140117_N  6800 non-null   float64\n",
            " 29  20140101_N  7600 non-null   float64\n",
            "dtypes: float64(27), int64(2), object(1)\n",
            "memory usage: 1.8+ MB\n",
            "None\n",
            "\n",
            ">>> TEST shape: (2845, 29)\n",
            "   Unnamed: 0  ID  20150720_N  20150602_N  20150517_N  20150501_N  20150415_N  \\\n",
            "0           0   1     7466.42     413.162     5761.00     5625.45     489.403   \n",
            "1           1   2     7235.26    6037.350     1027.56     6085.14    1618.050   \n",
            "2           2   3     7425.08    6969.980     1177.94     7408.93     861.061   \n",
            "3           3   4     7119.12    1731.620     6311.93     6441.61     465.979   \n",
            "4           4   5     7519.55    8130.260     1482.54     7879.53    1001.210   \n",
            "\n",
            "   20150330_N  20150314_N  20150226_N  ...  20140610_N  20140525_N  \\\n",
            "0     3923.84    3097.110     6766.42  ...     801.184     927.115   \n",
            "1     6668.54    2513.990     1051.69  ...    5533.470    5103.040   \n",
            "2     7644.43     814.458     1504.29  ...    1981.390    6204.540   \n",
            "3     7128.42    1649.120     6935.22  ...     959.344    5794.150   \n",
            "4     7937.60    4122.530     1094.51  ...    7636.070    6996.760   \n",
            "\n",
            "   20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  20140202_N  \\\n",
            "0     4704.14     6378.42     340.949    2695.570     527.268     4736.75   \n",
            "1     5216.12     4885.27    4366.790    1234.140    3298.110     6942.68   \n",
            "2     7021.69     5704.41    4897.450    1789.990    2206.100     6928.93   \n",
            "3     1045.57     5572.90     586.287     685.906    1287.000     6734.72   \n",
            "4     7413.43     4596.13    4511.700    1413.520    3283.940     7937.68   \n",
            "\n",
            "   20140117_N  20140101_N  \n",
            "0     601.843    6639.760  \n",
            "1    1070.440     842.101  \n",
            "2    1036.560     831.441  \n",
            "3     824.584    6883.610  \n",
            "4    1857.800    1336.920  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2845 entries, 0 to 2844\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Unnamed: 0  2845 non-null   int64  \n",
            " 1   ID          2845 non-null   int64  \n",
            " 2   20150720_N  2845 non-null   float64\n",
            " 3   20150602_N  2845 non-null   float64\n",
            " 4   20150517_N  2845 non-null   float64\n",
            " 5   20150501_N  2845 non-null   float64\n",
            " 6   20150415_N  2845 non-null   float64\n",
            " 7   20150330_N  2845 non-null   float64\n",
            " 8   20150314_N  2845 non-null   float64\n",
            " 9   20150226_N  2845 non-null   float64\n",
            " 10  20150210_N  2845 non-null   float64\n",
            " 11  20150125_N  2845 non-null   float64\n",
            " 12  20150109_N  2845 non-null   float64\n",
            " 13  20141117_N  2845 non-null   float64\n",
            " 14  20141101_N  2845 non-null   float64\n",
            " 15  20141016_N  2845 non-null   float64\n",
            " 16  20140930_N  2845 non-null   float64\n",
            " 17  20140813_N  2845 non-null   float64\n",
            " 18  20140626_N  2845 non-null   float64\n",
            " 19  20140610_N  2845 non-null   float64\n",
            " 20  20140525_N  2845 non-null   float64\n",
            " 21  20140509_N  2845 non-null   float64\n",
            " 22  20140423_N  2845 non-null   float64\n",
            " 23  20140407_N  2845 non-null   float64\n",
            " 24  20140322_N  2845 non-null   float64\n",
            " 25  20140218_N  2845 non-null   float64\n",
            " 26  20140202_N  2845 non-null   float64\n",
            " 27  20140117_N  2845 non-null   float64\n",
            " 28  20140101_N  2845 non-null   float64\n",
            "dtypes: float64(27), int64(2)\n",
            "memory usage: 644.7 KB\n",
            "None\n",
            "\n",
            "Found 27 NDVI columns:\n",
            "['20150720_N', '20150602_N', '20150517_N', '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N', '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N', '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N', '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N', '20140218_N', '20140202_N', '20140117_N', '20140101_N']\n",
            "\n",
            "Class counts:\n",
            "class\n",
            "forest        6159\n",
            "farm           841\n",
            "impervious     669\n",
            "grass          196\n",
            "water          105\n",
            "orchard         30\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in TRAIN:\n",
            "20140423_N    1760\n",
            "20140626_N    1600\n",
            "20140218_N    1440\n",
            "20141016_N    1440\n",
            "20150226_N    1360\n",
            "20141117_N    1280\n",
            "20140117_N    1200\n",
            "20150602_N    1200\n",
            "20140322_N    1120\n",
            "20150330_N    1120\n",
            "dtype: int64\n",
            "\n",
            "Missing values in TEST:\n",
            "20150720_N    0\n",
            "20150602_N    0\n",
            "20150517_N    0\n",
            "20150501_N    0\n",
            "20150415_N    0\n",
            "20150330_N    0\n",
            "20150314_N    0\n",
            "20150226_N    0\n",
            "20150210_N    0\n",
            "20150125_N    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rolling average smoothing (row-wise)\n",
        "train_df[ndvi_cols] = train_df[ndvi_cols].T.rolling(window=3, min_periods=1, center=True).mean().T\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].T.rolling(window=3, min_periods=1, center=True).mean().T\n"
      ],
      "metadata": {
        "id": "01XEYDDVg9Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where all NDVI values are NaN (very rare)\n",
        "train_df = train_df.dropna(subset=ndvi_cols, how='all').reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "5nirWweshBVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cap NDVI values to realistic bounds\n",
        "train_df[ndvi_cols] = train_df[ndvi_cols].clip(lower=-0.2, upper=0.9)\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].clip(lower=-0.2, upper=0.9)\n"
      ],
      "metadata": {
        "id": "L3rn_FufhDt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NDVI value range in TRAIN:\", train_df[ndvi_cols].min().min(), \"to\", train_df[ndvi_cols].max().max())\n",
        "print(\"NDVI value range in TEST:\", test_df[ndvi_cols].min().min(), \"to\", test_df[ndvi_cols].max().max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXq1JKldhHQm",
        "outputId": "a2403374-82ca-44c2-8a66-336b57aa0e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDVI value range in TRAIN: -0.2 to 0.9\n",
            "NDVI value range in TEST: -0.2 to 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolate across time for each sample (row-wise)\n",
        "train_df[ndvi_cols] = train_df[ndvi_cols].interpolate(axis=1, limit_direction='both')\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].interpolate(axis=1, limit_direction='both')\n"
      ],
      "metadata": {
        "id": "5APMEr1ghWni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill any remaining NaNs (after interpolation) with row-wise median\n",
        "train_df[ndvi_cols] = train_df[ndvi_cols].T.fillna(train_df[ndvi_cols].median(axis=1)).T\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].T.fillna(test_df[ndvi_cols].median(axis=1)).T\n"
      ],
      "metadata": {
        "id": "BwUq12rshXrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Any NaNs left in TRAIN NDVI?\", train_df[ndvi_cols].isnull().values.any())\n",
        "print(\"Any NaNs left in TEST NDVI?\", test_df[ndvi_cols].isnull().values.any())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkn6rgD7heNl",
        "outputId": "b766a198-9a0a-48ba-b3c7-bbc412b76fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Any NaNs left in TRAIN NDVI? False\n",
            "Any NaNs left in TEST NDVI? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def iqr_clip_rowwise(df, columns):\n",
        "    for idx in df.index:\n",
        "        row = df.loc[idx, columns]\n",
        "        Q1 = row.quantile(0.25)\n",
        "        Q3 = row.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        df.loc[idx, columns] = row.clip(lower=lower, upper=upper)\n",
        "    return df\n",
        "\n",
        "# Apply to both train and test\n",
        "train_df = iqr_clip_rowwise(train_df, ndvi_cols)\n",
        "test_df = iqr_clip_rowwise(test_df, ndvi_cols)\n"
      ],
      "metadata": {
        "id": "Jn1x-SaGhhVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with more than 50% NDVI values as zero (may indicate corrupted samples)\n",
        "threshold = int(len(ndvi_cols) * 0.5)\n",
        "train_df = train_df[~(train_df[ndvi_cols] == 0).sum(axis=1) > threshold].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "jRBAlySBiOX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "train_df[ndvi_cols] = train_df[ndvi_cols].apply(zscore, axis=1)\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].apply(zscore, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "6tmjQlXdiPlu",
        "outputId": "4cfc2991-b5f7-4158-fd9b-574724ccab29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Columns must be same length as key",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-601395921>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndvi_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndvi_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndvi_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndvi_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4299\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4358\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_not_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iset_not_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4377\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4379\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Apply z-score row-wise and reconstruct as DataFrame\n",
        "train_df[ndvi_cols] = pd.DataFrame(\n",
        "    zscore(train_df[ndvi_cols], axis=1, nan_policy='omit'),\n",
        "    columns=ndvi_cols,\n",
        "    index=train_df.index\n",
        ")\n",
        "\n",
        "test_df[ndvi_cols] = pd.DataFrame(\n",
        "    zscore(test_df[ndvi_cols], axis=1, nan_policy='omit'),\n",
        "    columns=ndvi_cols,\n",
        "    index=test_df.index\n",
        ")\n"
      ],
      "metadata": {
        "id": "dBZbm9ALiiGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train NDVI stats after outlier handling:\")\n",
        "print(train_df[ndvi_cols].describe().T)\n",
        "\n",
        "print(\"Any NaNs left?\", train_df[ndvi_cols].isnull().values.any(), test_df[ndvi_cols].isnull().values.any())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqysI7umikA0",
        "outputId": "c3060f88-54d2-4f38-d63e-5ae2c97a0d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train NDVI stats after outlier handling:\n",
            "            count  mean  std  min  25%  50%  75%  max\n",
            "20150720_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150602_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150517_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150501_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150415_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150330_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150314_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150226_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150210_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150125_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20150109_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20141117_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20141101_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20141016_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140930_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140813_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140626_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140610_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140525_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140509_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140423_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140407_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140322_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140218_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140202_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140117_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "20140101_N    0.0   NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
            "Any NaNs left? False False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Range = max - min\n",
        "train_df['ndvi_mean'] = train_df[ndvi_cols].mean(axis=1)\n",
        "train_df['ndvi_std'] = train_df[ndvi_cols].std(axis=1)\n",
        "train_df['ndvi_min'] = train_df[ndvi_cols].min(axis=1)\n",
        "train_df['ndvi_max'] = train_df[ndvi_cols].max(axis=1)\n",
        "train_df['ndvi_median'] = train_df[ndvi_cols].median(axis=1)\n",
        "train_df['ndvi_range'] = train_df['ndvi_max'] - train_df['ndvi_min']\n",
        "train_df['ndvi_skew'] = train_df[ndvi_cols].skew(axis=1)\n",
        "train_df['ndvi_kurtosis'] = train_df[ndvi_cols].kurtosis(axis=1)\n",
        "\n",
        "test_df['ndvi_mean'] = test_df[ndvi_cols].mean(axis=1)\n",
        "test_df['ndvi_std'] = test_df[ndvi_cols].std(axis=1)\n",
        "test_df['ndvi_min'] = test_df[ndvi_cols].min(axis=1)\n",
        "test_df['ndvi_max'] = test_df[ndvi_cols].max(axis=1)\n",
        "test_df['ndvi_median'] = test_df[ndvi_cols].median(axis=1)\n",
        "test_df['ndvi_range'] = test_df['ndvi_max'] - test_df['ndvi_min']\n",
        "test_df['ndvi_skew'] = test_df[ndvi_cols].skew(axis=1)\n",
        "test_df['ndvi_kurtosis'] = test_df[ndvi_cols].kurtosis(axis=1)\n"
      ],
      "metadata": {
        "id": "dykWUC7HivWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import linregress\n",
        "import numpy as np\n",
        "\n",
        "# Linear regression slope over time\n",
        "def compute_slope(row):\n",
        "    return linregress(range(len(ndvi_cols)), row.values).slope\n",
        "\n",
        "train_df['ndvi_slope'] = train_df[ndvi_cols].apply(compute_slope, axis=1)\n",
        "test_df['ndvi_slope'] = test_df[ndvi_cols].apply(compute_slope, axis=1)\n",
        "\n",
        "# Max difference between consecutive time steps\n",
        "train_df['ndvi_max_diff'] = train_df[ndvi_cols].diff(axis=1).abs().max(axis=1)\n",
        "test_df['ndvi_max_diff'] = test_df[ndvi_cols].diff(axis=1).abs().max(axis=1)\n",
        "\n",
        "# Number of local peaks (rough estimation of vegetation cycles)\n",
        "def count_peaks(row):\n",
        "    return ((row.shift(1) < row) & (row.shift(-1) < row)).sum()\n",
        "\n",
        "train_df['ndvi_peaks'] = train_df[ndvi_cols].apply(count_peaks, axis=1)\n",
        "test_df['ndvi_peaks'] = test_df[ndvi_cols].apply(count_peaks, axis=1)\n"
      ],
      "metadata": {
        "id": "nkOFHz6XkPS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into 3 seasonal blocks\n",
        "early_cols = ndvi_cols[:9]\n",
        "mid_cols = ndvi_cols[9:18]\n",
        "late_cols = ndvi_cols[18:]\n",
        "\n",
        "# Compute average NDVI in each season\n",
        "train_df['ndvi_early_mean'] = train_df[early_cols].mean(axis=1)\n",
        "train_df['ndvi_mid_mean'] = train_df[mid_cols].mean(axis=1)\n",
        "train_df['ndvi_late_mean'] = train_df[late_cols].mean(axis=1)\n",
        "\n",
        "test_df['ndvi_early_mean'] = test_df[early_cols].mean(axis=1)\n",
        "test_df['ndvi_mid_mean'] = test_df[mid_cols].mean(axis=1)\n",
        "test_df['ndvi_late_mean'] = test_df[late_cols].mean(axis=1)\n"
      ],
      "metadata": {
        "id": "suH5RypNkTQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib  # For saving the encoder\n",
        "\n",
        "# Step 1: Extract target\n",
        "y = train_df['class']\n",
        "\n",
        "# Step 2: Initialize and fit encoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Step 3: Replace original class column with encoded labels if needed\n",
        "train_df['class_encoded'] = y_encoded  # Optional for inspection\n",
        "\n",
        "# Step 4: Save encoder for use after prediction\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Optional: Check mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l20tL4eSkYoo",
        "outputId": "b9270eab-ce98-434f-a376-692816589b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['class'].unique())\n",
        "print(train_df['class'].isnull().sum())\n",
        "print(train_df[['ID', 'class']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWsW9-K6liay",
        "outputId": "afb743e2-7e28-495a-b43d-4e9b112e2a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "0\n",
            "Empty DataFrame\n",
            "Columns: [ID, class]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure original target is restored before encoding\n",
        "if 'class' not in train_df.columns:\n",
        "    train_df['class'] = original_class_column  # if you saved it earlier\n"
      ],
      "metadata": {
        "id": "DtUXrqnLloiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3QeuPFjlsXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib  # For saving the encoder\n",
        "\n",
        "# Step 1: Extract target\n",
        "y = train_df['class']\n",
        "\n",
        "# Step 2: Initialize and fit encoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Step 3: Replace original class column with encoded labels if needed\n",
        "train_df['class_encoded'] = y_encoded  # Optional for inspection\n",
        "\n",
        "# Step 4: Save encoder for use after prediction\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Optional: Check mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043d4b44-7884-49c3-a815-8cd5fb1b988f",
        "id": "qykOjycUl0te"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv2d-Nv3mNSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved encoder\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "\n",
        "# Assume y_preds_encoded is your predicted labels\n",
        "y_preds_labels = label_encoder.inverse_transform(y_preds_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "KaLGQuYPlDRV",
        "outputId": "eca0917e-fddb-42f1-951c-b5ddf0f1c6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_preds_encoded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1175004904>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assume y_preds_encoded is your predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_preds_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_preds_encoded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['class'].head(10))\n",
        "print(train_df['class'].unique())\n",
        "print(train_df['class'].dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arvWNVJwmPBh",
        "outputId": "044224dc-9dee-4df9-a81d-942f5a8a3517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: class, dtype: object)\n",
            "[]\n",
            "object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['class'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vIx41vlmYnI",
        "outputId": "006d703a-f325-4394-c1ac-d807b173e210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['class'] = train_df['class'].str.strip()  # remove extra spaces\n",
        "train_df = train_df[train_df['class'].notna()]     # drop NaNs\n"
      ],
      "metadata": {
        "id": "F7f6UZSJmeO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = train_df['class']\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ons-XN5mi8Q",
        "outputId": "2b80cf40-b9b7-417e-c781-d0cff8af16ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['class'].unique())\n",
        "print(train_df['class'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBTDU1QAmqhg",
        "outputId": "2de9ad6b-914c-450f-f2a4-84c7e7408cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload just the target labels from original train.csv\n",
        "original_train = pd.read_csv('hacktrain.csv')  # replace with your actual file path\n",
        "\n",
        "# Merge back the 'class' column into your cleaned train_df using ID\n",
        "train_df = train_df.merge(original_train[['ID', 'class']], on='ID', how='left')\n",
        "\n",
        "# Now check again\n",
        "print(train_df['class'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "eb9Lomipm93a",
        "outputId": "5c69cdce-6321-48bf-9516-76fbabcc8d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MergeError",
          "evalue": "Passing 'suffixes' which cause duplicate columns {'class_x'} is not allowed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2468425138>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Merge back the 'class' column into your cleaned train_df using ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Now check again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         )\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         result = self._reindex_and_concat(\n\u001b[0m\u001b[1;32m    889\u001b[0m             \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mdups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m         raise MergeError(\n\u001b[0m\u001b[1;32m   2758\u001b[0m             \u001b[0;34mf\"Passing 'suffixes' which cause duplicate columns {set(dups)} is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;34mf\"not allowed.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'class_x'} is not allowed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop the broken 'class' column if it already exists\n",
        "if 'class' in train_df.columns:\n",
        "    train_df = train_df.drop(columns=['class'])\n",
        "\n",
        "# 2. Load original class labels\n",
        "original_train = pd.read_csv('hacktrain.csv')  # Update filename if needed\n",
        "\n",
        "# 3. Merge correctly using 'ID'\n",
        "train_df = train_df.merge(original_train[['ID', 'class']], on='ID', how='left')\n",
        "\n",
        "# 4. Check it worked\n",
        "print(train_df['class'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De8dNb3QnPUl",
        "outputId": "4bff528f-6f40-4ef3-f56d-3a2c7aa0df1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = train_df['class'].str.strip()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"✅ Label mapping:\", dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsCXvXuunUPL",
        "outputId": "e2a0c0f2-d80d-45b7-d277-9411311cbe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LOZqsr68nys5",
        "outputId": "5b376529-079a-428f-f1c3-46b248372630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b011562-713e-4838-88b2-dbe4c1cc8531\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b011562-713e-4838-88b2-dbe4c1cc8531\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hacktrain.csv to hacktrain (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load original raw hactrain data to get class\n",
        "import pandas as pd\n",
        "original_train = pd.read_csv('hacktrain.csv')\n",
        "\n",
        "# Step 2: Merge 'class' labels back into cleaned train_df using ID\n",
        "train_df = train_df.merge(original_train[['ID', 'class']], on='ID', how='left')\n",
        "\n",
        "# Step 3: Verify if class column has been restored\n",
        "print(\"Class label distribution:\\n\", train_df['class'].value_counts())\n",
        "\n",
        "# Step 4: Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df['label'] = le.fit_transform(train_df['class'])\n",
        "\n",
        "# Show the mapping\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qTe3gVuaoHgr",
        "outputId": "61521600-3bd1-4eb8-f7a7-7edc9c6300ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MergeError",
          "evalue": "Passing 'suffixes' which cause duplicate columns {'class_x'} is not allowed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-2446502118>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 2: Merge 'class' labels back into cleaned train_df using ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Step 3: Verify if class column has been restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         )\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         result = self._reindex_and_concat(\n\u001b[0m\u001b[1;32m    889\u001b[0m             \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0mdups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m         raise MergeError(\n\u001b[0m\u001b[1;32m   2758\u001b[0m             \u001b[0;34mf\"Passing 'suffixes' which cause duplicate columns {set(dups)} is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;34mf\"not allowed.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'class_x'} is not allowed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Step 1: Load the original hacktrain.csv to access class labels\n",
        "original_train = pd.read_csv('hacktrain.csv')\n",
        "\n",
        "# Step 2: Drop existing 'class' column from train_df (if present)\n",
        "if 'class' in train_df.columns:\n",
        "    train_df = train_df.drop(columns=['class'])\n",
        "\n",
        "# Step 3: Merge labels back using 'ID'\n",
        "train_df = train_df.merge(original_train[['ID', 'class']], on='ID', how='left')\n",
        "\n",
        "# Step 4: Check class distribution to confirm success\n",
        "print(\"Class label distribution:\\n\", train_df['class'].value_counts())\n",
        "\n",
        "# Step 5: Encode string labels to numeric\n",
        "le = LabelEncoder()\n",
        "train_df['label'] = le.fit_transform(train_df['class'])\n",
        "\n",
        "# Step 6: Show label mapping\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2poOqApomnD",
        "outputId": "0411e176-3d25-46b7-cbd1-9228f9064ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label distribution:\n",
            " Series([], Name: count, dtype: int64)\n",
            "✅ Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load original file\n",
        "original_train = pd.read_csv('hacktrain.csv')\n",
        "\n",
        "# Show first few rows\n",
        "print(original_train.head())\n",
        "\n",
        "# Check if 'ID' and 'class' columns exist\n",
        "print(original_train.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqIIcpfWo-dZ",
        "outputId": "cf7864f8-62d6-44df-bc31-b2ec99ce1b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  ID  class  20150720_N  20150602_N  20150517_N  20150501_N  \\\n",
            "0           0   1  water    637.5950     658.668   -1882.030    -1924.36   \n",
            "1           1   2  water    634.2400     593.705   -1625.790    -1672.32   \n",
            "2           3   4  water     58.0174   -1599.160         NaN    -1052.63   \n",
            "3           4   5  water     72.5180         NaN     380.436    -1256.93   \n",
            "4           7   8  water   1136.4400         NaN         NaN     1647.83   \n",
            "\n",
            "   20150415_N  20150330_N  20150314_N  ...  20140610_N  20140525_N  \\\n",
            "0     997.904   -1739.990     630.087  ...         NaN   -1043.160   \n",
            "1     914.198    -692.386     707.626  ...         NaN    -933.934   \n",
            "2         NaN   -1564.630         NaN  ...    -1025.88     368.622   \n",
            "3     515.805   -1413.180    -802.942  ...    -1813.95     155.624   \n",
            "4    1935.800         NaN    2158.980  ...     1535.00    1959.430   \n",
            "\n",
            "   20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  20140202_N  \\\n",
            "0   -1942.490     267.138         NaN         NaN     211.328   -2203.020   \n",
            "1    -625.385     120.059     364.858     476.972     220.878   -2250.000   \n",
            "2         NaN   -1227.800     304.621         NaN     369.214   -2202.120   \n",
            "3         NaN    -924.073     432.150     282.833     298.320   -2197.360   \n",
            "4    -279.317    -384.915    -113.406    1020.720    1660.650    -116.801   \n",
            "\n",
            "   20140117_N  20140101_N  \n",
            "0    -1180.19     433.906  \n",
            "1    -1360.56     524.075  \n",
            "2         NaN   -1343.550  \n",
            "3         NaN    -826.727  \n",
            "4     -568.05   -1357.140  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "Index(['Unnamed: 0', 'ID', 'class', '20150720_N', '20150602_N', '20150517_N',\n",
            "       '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N',\n",
            "       '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N',\n",
            "       '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N',\n",
            "       '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N',\n",
            "       '20140218_N', '20140202_N', '20140117_N', '20140101_N'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of matching IDs:\",\n",
        "      len(set(train_df['ID']).intersection(set(original_train['ID']))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Fqlst9pEP0",
        "outputId": "b3ed4931-6721-4fe1-bab8-d7d1964f19aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matching IDs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove old class column if present\n",
        "if 'class' in train_df.columns:\n",
        "    train_df = train_df.drop(columns=['class'])\n",
        "\n",
        "# Merge using correct source\n",
        "train_df = train_df.merge(original_train[['ID', 'class']], on='ID', how='left')\n",
        "\n",
        "# Confirm if labels are now present\n",
        "print(\"Class distribution after merge:\\n\", train_df['class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZh-uxrOpXl_",
        "outputId": "29468b95-ab4c-486d-d9da-55854cad1c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after merge:\n",
            " Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df['label'] = le.fit_transform(train_df['class'])\n",
        "\n",
        "# Save mapping\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJhf_6ozpaPc",
        "outputId": "9104f283-af9c-486c-96ed-c693f93361c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_train.head())\n",
        "print(original_train.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc1V5s7_peCG",
        "outputId": "7f72c737-f9a7-4936-9e72-5a01e3edf5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  ID  class  20150720_N  20150602_N  20150517_N  20150501_N  \\\n",
            "0           0   1  water    637.5950     658.668   -1882.030    -1924.36   \n",
            "1           1   2  water    634.2400     593.705   -1625.790    -1672.32   \n",
            "2           3   4  water     58.0174   -1599.160         NaN    -1052.63   \n",
            "3           4   5  water     72.5180         NaN     380.436    -1256.93   \n",
            "4           7   8  water   1136.4400         NaN         NaN     1647.83   \n",
            "\n",
            "   20150415_N  20150330_N  20150314_N  ...  20140610_N  20140525_N  \\\n",
            "0     997.904   -1739.990     630.087  ...         NaN   -1043.160   \n",
            "1     914.198    -692.386     707.626  ...         NaN    -933.934   \n",
            "2         NaN   -1564.630         NaN  ...    -1025.88     368.622   \n",
            "3     515.805   -1413.180    -802.942  ...    -1813.95     155.624   \n",
            "4    1935.800         NaN    2158.980  ...     1535.00    1959.430   \n",
            "\n",
            "   20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  20140202_N  \\\n",
            "0   -1942.490     267.138         NaN         NaN     211.328   -2203.020   \n",
            "1    -625.385     120.059     364.858     476.972     220.878   -2250.000   \n",
            "2         NaN   -1227.800     304.621         NaN     369.214   -2202.120   \n",
            "3         NaN    -924.073     432.150     282.833     298.320   -2197.360   \n",
            "4    -279.317    -384.915    -113.406    1020.720    1660.650    -116.801   \n",
            "\n",
            "   20140117_N  20140101_N  \n",
            "0    -1180.19     433.906  \n",
            "1    -1360.56     524.075  \n",
            "2         NaN   -1343.550  \n",
            "3         NaN    -826.727  \n",
            "4     -568.05   -1357.140  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "Index(['Unnamed: 0', 'ID', 'class', '20150720_N', '20150602_N', '20150517_N',\n",
            "       '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N',\n",
            "       '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N',\n",
            "       '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N',\n",
            "       '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N',\n",
            "       '20140218_N', '20140202_N', '20140117_N', '20140101_N'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "NcvHqVBQpvdq",
        "outputId": "442e9dfc-1022-49b3-932b-2e43ac952007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a16eb91-e7a9-4069-a04a-ef564a560d01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1a16eb91-e7a9-4069-a04a-ef564a560d01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hacktrain.csv to hacktrain (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the clean source again\n",
        "original_train = pd.read_csv('hacktrain.csv')\n",
        "\n",
        "# Just keep ID and class\n",
        "id_class_map = original_train[['ID', 'class']].copy()\n",
        "\n",
        "# Drop old class column from your working dataframe if needed\n",
        "if 'class' in train_df.columns:\n",
        "    train_df.drop(columns=['class'], inplace=True)\n",
        "\n",
        "# Now merge safely\n",
        "train_df = train_df.merge(id_class_map, on='ID', how='left')\n",
        "\n",
        "# Confirm it's there\n",
        "print(\"✅ Class distribution:\\n\", train_df['class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMf3uOVdqCk5",
        "outputId": "86693444-b31c-4053-84b1-9d7b7e488bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class distribution:\n",
            " Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize and fit\n",
        "le = LabelEncoder()\n",
        "train_df['label'] = le.fit_transform(train_df['class'])\n",
        "\n",
        "# Store mapping for later inverse transform\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqSqdTikqH5L",
        "outputId": "d7459a2a-ee66-4ade-fb1a-975327e348d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib  # for saving the encoder\n",
        "\n",
        "# 1. Initialize and fit label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['class'])\n",
        "\n",
        "# 2. Print label mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n",
        "\n",
        "# 3. Save encoder to use during submission\n",
        "joblib.dump(label_encoder, '/mnt/data/label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "MmMBjXLUqi6y",
        "outputId": "8c0e9d04-409f-42bc-9d49-6be4674050a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/label_encoder.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-3903644797>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 3. Save encoder to use during submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/mnt/data/label_encoder.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/label_encoder.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 5 values of 'class':\", train_df['class'].head())\n",
        "print(\"Unique values:\", train_df['class'].unique())\n",
        "print(\"Value counts:\\n\", train_df['class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIYqN5ujrxTy",
        "outputId": "f9ae6fe0-0bd8-46e3-e74c-24b872f2adbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 values of 'class': Series([], Name: class, dtype: object)\n",
            "Unique values: []\n",
            "Value counts:\n",
            " Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Re-create directory if not exists\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Apply label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['class'])\n",
        "\n",
        "# Show the mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n",
        "\n",
        "# Save the encoder to disk (in current working dir)\n",
        "joblib.dump(label_encoder, 'models/label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyNjOf_6r34y",
        "outputId": "87201042-1946-48cc-effb-e8580a742994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns)\n",
        "print(train['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "kV8zdphb3GUM",
        "outputId": "56a23254-8a0b-4da1-8aa2-ef07a7638e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-2725136464>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'] = train['label'].astype(str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Uq0vpbGv3OrV",
        "outputId": "e26667c4-a593-4f5b-857d-f9afc2081429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-1220368388>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['label'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "70b47lzK4Lh-",
        "outputId": "ca982332-c068-4ff7-b94a-b37634129263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-3616311841>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.columns)\n",
        "print(train['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "J1H4S_H84Y6-",
        "outputId": "cc39f999-79ac-4ca1-e127-b4086ec04948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-2725136464>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG: Check if 'label' exists\n",
        "if 'label' not in train.columns:\n",
        "    raise KeyError(\"Column 'label' not found in train DataFrame\")\n",
        "\n",
        "# DEBUG: Print unique values in label\n",
        "print(\"Unique labels before encoding:\", train['label'].unique())\n",
        "\n",
        "# Safe conversion\n",
        "train['label'] = train['label'].astype(str)\n",
        "\n",
        "# Apply LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['label'])\n",
        "print(\"Labels after encoding:\", train['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D4LM1LwN4a0h",
        "outputId": "475d4660-eb41-42f9-b4dc-60d4443f3140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-457641741>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DEBUG: Check if 'label' exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'label'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column 'label' not found in train DataFrame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# DEBUG: Print unique values in label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['label'])\n"
      ],
      "metadata": {
        "id": "GKou9l0H55iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Rename for clarity (optional)\n",
        "train = train_df.copy()\n",
        "\n",
        "# Confirm label column\n",
        "print(\"Unique classes before encoding:\", train['class'].unique())\n",
        "\n",
        "# Convert to string if needed\n",
        "train['class'] = train['class'].astype(str)\n",
        "\n",
        "# Apply LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['class'])\n",
        "\n",
        "# Preview\n",
        "print(\"Labels after encoding:\", train['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHM0e2Kt5e5z",
        "outputId": "e6dd8595-f0b8-424f-8866-c5221d318f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes before encoding: []\n",
            "Labels after encoding: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n",
        "print(train_df.head())\n",
        "print(train_df['class'].isnull().sum(), \"/\", len(train_df))  # Number of missing labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNM1yGkF6MhP",
        "outputId": "ea80cd23-0e1b-447a-c868-b749fc691bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'ID', 'class_x', '20150720_N', '20150602_N', '20150517_N',\n",
            "       '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N',\n",
            "       '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N',\n",
            "       '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N',\n",
            "       '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N',\n",
            "       '20140218_N', '20140202_N', '20140117_N', '20140101_N', 'ndvi_mean',\n",
            "       'ndvi_std', 'ndvi_min', 'ndvi_max', 'ndvi_median', 'ndvi_range',\n",
            "       'ndvi_skew', 'ndvi_kurtosis', 'ndvi_slope', 'ndvi_max_diff',\n",
            "       'ndvi_peaks', 'ndvi_early_mean', 'ndvi_mid_mean', 'ndvi_late_mean',\n",
            "       'class_encoded', 'class_y', 'label', 'class'],\n",
            "      dtype='object')\n",
            "Empty DataFrame\n",
            "Columns: [Unnamed: 0, ID, class_x, 20150720_N, 20150602_N, 20150517_N, 20150501_N, 20150415_N, 20150330_N, 20150314_N, 20150226_N, 20150210_N, 20150125_N, 20150109_N, 20141117_N, 20141101_N, 20141016_N, 20140930_N, 20140813_N, 20140626_N, 20140610_N, 20140525_N, 20140509_N, 20140423_N, 20140407_N, 20140322_N, 20140218_N, 20140202_N, 20140117_N, 20140101_N, ndvi_mean, ndvi_std, ndvi_min, ndvi_max, ndvi_median, ndvi_range, ndvi_skew, ndvi_kurtosis, ndvi_slope, ndvi_max_diff, ndvi_peaks, ndvi_early_mean, ndvi_mid_mean, ndvi_late_mean, class_encoded, class_y, label, class]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 48 columns]\n",
            "0 / 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "wvqQtC416Z4l",
        "outputId": "30d3bdfd-c2e1-47e1-b0eb-b2cde029a87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b1772a40-10bb-4393-beb5-ac146912675c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b1772a40-10bb-4393-beb5-ac146912675c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hacktrain.csv to hacktrain (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('hacktrain.csv')\n",
        "\n",
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97qlx6yj6QrR",
        "outputId": "f39226dc-0013-41ff-80ff-e683255beb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'ID', 'class', '20150720_N', '20150602_N', '20150517_N',\n",
            "       '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N',\n",
            "       '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N',\n",
            "       '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N',\n",
            "       '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N',\n",
            "       '20140218_N', '20140202_N', '20140117_N', '20140101_N'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0  ID  class  20150720_N  20150602_N  20150517_N  20150501_N  \\\n",
            "0           0   1  water    637.5950     658.668   -1882.030    -1924.36   \n",
            "1           1   2  water    634.2400     593.705   -1625.790    -1672.32   \n",
            "2           3   4  water     58.0174   -1599.160         NaN    -1052.63   \n",
            "3           4   5  water     72.5180         NaN     380.436    -1256.93   \n",
            "4           7   8  water   1136.4400         NaN         NaN     1647.83   \n",
            "\n",
            "   20150415_N  20150330_N  20150314_N  ...  20140610_N  20140525_N  \\\n",
            "0     997.904   -1739.990     630.087  ...         NaN   -1043.160   \n",
            "1     914.198    -692.386     707.626  ...         NaN    -933.934   \n",
            "2         NaN   -1564.630         NaN  ...    -1025.88     368.622   \n",
            "3     515.805   -1413.180    -802.942  ...    -1813.95     155.624   \n",
            "4    1935.800         NaN    2158.980  ...     1535.00    1959.430   \n",
            "\n",
            "   20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  20140202_N  \\\n",
            "0   -1942.490     267.138         NaN         NaN     211.328   -2203.020   \n",
            "1    -625.385     120.059     364.858     476.972     220.878   -2250.000   \n",
            "2         NaN   -1227.800     304.621         NaN     369.214   -2202.120   \n",
            "3         NaN    -924.073     432.150     282.833     298.320   -2197.360   \n",
            "4    -279.317    -384.915    -113.406    1020.720    1660.650    -116.801   \n",
            "\n",
            "   20140117_N  20140101_N  \n",
            "0    -1180.19     433.906  \n",
            "1    -1360.56     524.075  \n",
            "2         NaN   -1343.550  \n",
            "3         NaN    -826.727  \n",
            "4     -568.05   -1357.140  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(train_df.shape)\n",
        "print(train_df.dropna(subset=['class']).shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBCmf4w-6wA3",
        "outputId": "e4ee5216-cd67-41d1-a57b-d5fd3bff7424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 48)\n",
            "(0, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df[ndvi_cols].isnull().all(axis=1).sum(), \"/\", len(train_df))  # Number of rows where all NDVI values are NaN\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svEFWy_m7YMh",
        "outputId": "4c53fca2-15cd-4188-8758-8ad8e9f080e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 30)\n",
            "0 / 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload original file\n",
        "df = pd.read_csv(\"hacktrain.csv\")\n",
        "\n",
        "# Identify NDVI columns again\n",
        "ndvi_cols = [col for col in df.columns if col.endswith('_N')]\n",
        "\n",
        "# Print count of rows with all NDVI missing\n",
        "print(\"Rows with all NDVI NaN:\", df[ndvi_cols].isnull().all(axis=1).sum(), \"/\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqlU8BCL7zN2",
        "outputId": "3cb05fe7-731a-48e8-fb4d-eac987d14d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with all NDVI NaN: 0 / 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIOE5Mj-75Iz",
        "outputId": "51032c13-094a-4fe9-c668-d32ee3a47920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'ID', 'class', '20150720_N', '20150602_N', '20150517_N',\n",
            "       '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N',\n",
            "       '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N',\n",
            "       '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N',\n",
            "       '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N',\n",
            "       '20140218_N', '20140202_N', '20140117_N', '20140101_N'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqfcReX8X_g",
        "outputId": "b1fc061f-ec5f-4b28-884c-f6c3772e565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class\n",
            "forest        6159\n",
            "farm           841\n",
            "impervious     669\n",
            "grass          196\n",
            "water          105\n",
            "orchard         30\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit on correct column\n",
        "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "# Print mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyJVFQK18eMG",
        "outputId": "62d9e90e-0774-4b63-8db4-bd5955600175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {'farm': np.int64(0), 'forest': np.int64(1), 'grass': np.int64(2), 'impervious': np.int64(3), 'orchard': np.int64(4), 'water': np.int64(5)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['class'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K3w5xjr81sC",
        "outputId": "65571976-9932-4e29-b11f-3d80893d3dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['water' 'forest' 'impervious' 'farm' 'grass' 'orchard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Step 1: Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Step 2: Fit and transform the class column in your df\n",
        "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "# Step 3: Create and display mapping\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n",
        "\n",
        "# Step 4: Save encoder for later (for decoding predictions)\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Zs1QyX9Hbn",
        "outputId": "07902ca1-09f8-43c2-934d-897393b27ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {'farm': np.int64(0), 'forest': np.int64(1), 'grass': np.int64(2), 'impervious': np.int64(3), 'orchard': np.int64(4), 'water': np.int64(5)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv(\"hacktrain.csv\")\n",
        "\n",
        "# 1. Encode the target\n",
        "label_encoder = LabelEncoder()\n",
        "df['class_encoded'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "# Optional: save encoder for submission\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "# 2. Prepare X and y\n",
        "X = df.drop(columns=['Unnamed: 0', 'ID', 'class', 'class_encoded'])\n",
        "y = df['class_encoded']\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Optional: Save scaler for submission use\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# 4. Initialize logistic regression model\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 5. Cross-validation setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 6. Evaluate using Accuracy and Macro F1-score\n",
        "accuracy_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "f1_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring=make_scorer(f1_score, average='macro'))\n",
        "\n",
        "# 7. Print final scores\n",
        "print(f\" Cross-validated Accuracy: {accuracy_scores.mean():.4f}\")\n",
        "print(f\" Cross-validated Macro F1-score: {f1_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "DGmPLBHv93w7",
        "outputId": "a10624e8-72db-412d-fd39-8c7594164775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1222, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-1146949595>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# 6. Evaluate using Accuracy and Macro F1-score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0maccuracy_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mf1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# For callable scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1222, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check total missing values\n",
        "print(\"Missing values before:\", X.isna().sum().sum())\n",
        "\n",
        "# Fill remaining NaNs with row-wise median (best for NDVI stability)\n",
        "X_imputed = X.apply(lambda row: row.fillna(row.median()), axis=1)\n",
        "\n",
        "# Confirm\n",
        "print(\"Missing values after:\", X_imputed.isna().sum().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6sjOYp1-Xxg",
        "outputId": "496fed9c-3f67-470b-affe-2fb49070cb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before: 25040\n",
            "Missing values after: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "import joblib\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Save scaler for test-time\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Set up model\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Stratified 5-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Accuracy and macro F1-score\n",
        "acc_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "f1_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring=make_scorer(f1_score, average='macro'))\n",
        "\n",
        "print(f\"✅ Accuracy (CV): {acc_scores.mean():.4f}\")\n",
        "print(f\"✅ Macro F1 (CV): {f1_scores.mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "T-xN0o7o-bHc",
        "outputId": "04021810-6f92-4e4d-ab72-0394b85c6122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-4253842896>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Accuracy and macro F1-score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0macc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mf1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Combined scoring to reduce total time\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'macro_f1': make_scorer(f1_score, average='macro')\n",
        "}\n",
        "\n",
        "results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "\n",
        "print(f\" Accuracy (CV): {results['test_accuracy'].mean():.4f}\")\n",
        "print(f\" Macro F1 (CV): {results['test_macro_f1'].mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "vWyb-yJA_TCy",
        "outputId": "75d0927e-cf79-41d7-cb41-9def4ee07d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-845234435>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Accuracy (CV): {results['test_accuracy'].mean():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# Train on entire data directly\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='lbfgs',  # faster than saga\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_scaled, y)\n",
        "joblib.dump(model, \"logreg_model.pkl\")\n",
        "\n",
        "print(\"✅ Logistic Regression model trained on full data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4n1lMS6_gy8",
        "outputId": "3f4c963d-d69b-4314-f4a5-e1be849309e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logistic Regression model trained on full data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# X_final: your final feature dataframe (already cleaned)\n",
        "# y: your encoded labels (as used before)\n",
        "\n",
        "# 1. Scale\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "# 2. Save for later prediction\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# 3. Define model\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',  # Or 'lbfgs'\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 4. Setup stratified 5-fold CV\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 5. Run CV and evaluate\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro')\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring, return_train_score=True)\n",
        "\n",
        "# 6. Print results\n",
        "print(\"✅ Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy     : {cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"Mean Macro F1-Score: {cv_results['test_f1_macro'].mean():.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rQBhsoRa_jax",
        "outputId": "060574d4-2a89-47d2-e681-31aaf144207a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_final' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-3083650168>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 1. Scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 2. Save for later prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_final' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define features and labels\n",
        "X_final = df.drop(columns=['ID', 'class'])  # Features only\n",
        "y = df['class_encoded']  # Encoded labels from LabelEncoder\n",
        "\n",
        "# 2. Now scale and continue with the rest\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "# Save the scaler (optional for later prediction)\n",
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# 3. Define the model again\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 4. Setup Stratified 5-Fold Cross-Validation\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'f1_macro': make_scorer(f1_score, average='macro')\n",
        "}\n",
        "\n",
        "# 5. Cross-validation\n",
        "cv_results = cross_validate(model, X_scaled, y, cv=cv, scoring=scoring)\n",
        "\n",
        "# 6. Print results\n",
        "print(\"✅ Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy      : {cv_results['test_accuracy'].mean():.4f}\")\n",
        "print(f\"Mean Macro F1-Score: {cv_results['test_f1_macro'].mean():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "lmhDhOjcALbW",
        "outputId": "867d3eb3-7e27-4017-9736-bca7f71ba191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1222, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-2961008199>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 5. Cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# 6. Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# For callable scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1222, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 1107, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "\n",
        "# Load test data if not already done\n",
        "# test_df = pd.read_csv('/path/to/hacktest.csv')  # Already loaded as test_df\n",
        "\n",
        "# 1. Drop columns not used in training\n",
        "drop_cols = ['Unnamed: 0', 'ID']  # you may adjust if more columns were dropped earlier\n",
        "\n",
        "# Align test with train columns\n",
        "X_test_raw = test_df.drop(columns=drop_cols)\n",
        "\n",
        "# 2. Fill missing values in test (same strategy as train: median)\n",
        "X_test_filled = X_test_raw.fillna(X_test_raw.median())\n",
        "\n",
        "# 3. Scale using the same scaler as training\n",
        "X_test_scaled = scaler.transform(X_test_filled)\n",
        "\n",
        "# 4. Train model on full training data\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=1500,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# 5. Predict on test data\n",
        "test_preds_encoded = model.predict(X_test_scaled)\n",
        "\n",
        "# 6. Inverse transform encoded labels to original class names\n",
        "test_preds = label_encoder.inverse_transform(test_preds_encoded)\n",
        "\n",
        "# 7. Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'class': test_preds\n",
        "})\n",
        "\n",
        "# 8. Save as CSV (Kaggle submission format)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"✅ Submission file saved as submission.csv\")\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "F-jUFyvHA8u-",
        "outputId": "fd0c7a0b-8ceb-4fcd-f58c-1b55cecd75bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ndvi_early_mean\n- ndvi_kurtosis\n- ndvi_late_mean\n- ndvi_max\n- ndvi_max_diff\n- ...\nFeature names seen at fit time, yet now missing:\n- Unnamed: 0\n- class_encoded\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-2628236653>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 3. Scale using the same scaler as training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_filled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# 4. Train model on full training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \"\"\"\n\u001b[0;32m-> 2919\u001b[0;31m     \u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Feature names must be in the same order as they were in fit.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ndvi_early_mean\n- ndvi_kurtosis\n- ndvi_late_mean\n- ndvi_max\n- ndvi_max_diff\n- ...\nFeature names seen at fit time, yet now missing:\n- Unnamed: 0\n- class_encoded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define final features used for model\n",
        "drop_cols = ['Unnamed: 0', 'ID', 'class', 'class_encoded']\n",
        "X_final = df.drop(columns=drop_cols)\n",
        "y = df['class_encoded']\n",
        "\n",
        "# 2. Fill NaNs\n",
        "X_final = X_final.fillna(X_final.median())\n",
        "\n",
        "# 3. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "# 4. Train model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=1500,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# =========================\n",
        "# Test Data Preprocessing\n",
        "# =========================\n",
        "\n",
        "# 5. Apply same column logic to test\n",
        "X_test = test_df[X_final.columns]  # Ensure same order and columns\n",
        "\n",
        "# 6. Fill missing values\n",
        "X_test = X_test.fillna(X_test.median())\n",
        "\n",
        "# 7. Scale using same scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 8. Predict\n",
        "test_preds_encoded = model.predict(X_test_scaled)\n",
        "test_preds = label_encoder.inverse_transform(test_preds_encoded)\n",
        "\n",
        "# 9. Prepare submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'class': test_preds\n",
        "})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"✅ Final submission file saved as submission.csv\")\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "a37aJLSABM1j",
        "outputId": "0bcad259-6018-4a3b-f987-4c1fb7e8f11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final submission file saved as submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID       class\n",
              "0   1  impervious\n",
              "1   2  impervious\n",
              "2   3  impervious\n",
              "3   4  impervious\n",
              "4   5  impervious"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6076529-24f4-4be8-ae34-9b21300d572f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>impervious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>impervious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>impervious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>impervious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>impervious</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6076529-24f4-4be8-ae34-9b21300d572f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6076529-24f4-4be8-ae34-9b21300d572f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6076529-24f4-4be8-ae34-9b21300d572f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5ffc26f3-3bae-49a1-85c4-82a8df14f798\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ffc26f3-3bae-49a1-85c4-82a8df14f798')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5ffc26f3-3bae-49a1-85c4-82a8df14f798 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 2845,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 821,\n        \"min\": 1,\n        \"max\": 2845,\n        \"num_unique_values\": 2845,\n        \"samples\": [\n          416,\n          2234,\n          1150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"impervious\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "SWsvfwj_BjXC",
        "outputId": "c7500622-b3b1-4f8e-f2a9-d972e1a123b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "forest        6159\n",
              "farm           841\n",
              "impervious     669\n",
              "grass          196\n",
              "water          105\n",
              "orchard         30\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>forest</th>\n",
              "      <td>6159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>farm</th>\n",
              "      <td>841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>impervious</th>\n",
              "      <td>669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grass</th>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>water</th>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>orchard</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# 1. Setup: Use only raw NDVI columns\n",
        "ndvi_cols = [col for col in df.columns if '_N' in col]\n",
        "\n",
        "X_train = df[ndvi_cols]\n",
        "y_train = df['class_encoded']\n",
        "\n",
        "# 2. Fill NaNs\n",
        "X_train = X_train.fillna(X_train.median())\n",
        "test_df[ndvi_cols] = test_df[ndvi_cols].fillna(X_train.median())  # same median\n",
        "\n",
        "# 3. Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(test_df[ndvi_cols])\n",
        "\n",
        "# 4. Train final model\n",
        "model = LogisticRegression(\n",
        "    multi_class='multinomial',\n",
        "    solver='saga',\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 5. Predict\n",
        "y_pred_encoded = model.predict(X_test_scaled)\n",
        "\n",
        "# 6. Inverse transform\n",
        "submission_preds = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# 7. Create submission file\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'class': submission_preds\n",
        "})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"✅ Submission saved as 'submission.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjTHzTSSB0f0",
        "outputId": "a903df84-7544-47bc-aac7-bd02a867c889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission saved as 'submission.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "VsfublnqBlSa",
        "outputId": "b47d2b55-76e0-4bec-ddf8-f93844f97778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "forest        6159\n",
              "farm           841\n",
              "impervious     669\n",
              "grass          196\n",
              "water          105\n",
              "orchard         30\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>forest</th>\n",
              "      <td>6159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>farm</th>\n",
              "      <td>841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>impervious</th>\n",
              "      <td>669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grass</th>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>water</th>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>orchard</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_preds = model.predict(X_train_scaled)\n",
        "print(classification_report(y_train, train_preds, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZl5_ySCC4o",
        "outputId": "ab87cfd2-8692-4b0c-b816-7d6a6b830377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.40      0.51      0.45       841\n",
            "      forest       0.97      0.57      0.72      6159\n",
            "       grass       0.17      0.64      0.26       196\n",
            "  impervious       0.54      0.41      0.46       669\n",
            "     orchard       0.03      0.90      0.05        30\n",
            "       water       0.09      0.90      0.16       105\n",
            "\n",
            "    accuracy                           0.56      8000\n",
            "   macro avg       0.37      0.65      0.35      8000\n",
            "weighted avg       0.84      0.56      0.65      8000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9DMISLy0Cca-",
        "outputId": "e3d737d8-8762-48f1-8932-a95346fe9740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68391a36-fbbe-4cb8-bf38-f6c672d0b2e4\", \"submission.csv\", 30197)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}